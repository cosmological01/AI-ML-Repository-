{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02312fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganesh\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0, Loss: 0.6931\n",
      "Epoch  500, Loss: 0.5983\n",
      "Epoch 1000, Loss: 0.5983\n",
      "Epoch 1500, Loss: 0.5983\n",
      "Epoch 2000, Loss: 0.5983\n",
      "Epoch 2500, Loss: 0.5983\n",
      "\n",
      "Final Training Accuracy: 68.33%\n",
      "\n",
      "--- Sample Predictions ---\n",
      "Passenger 1 | Prob: 0.808 | Pred: Survived | Actual: Survived\n",
      "Passenger 2 | Prob: 0.903 | Pred: Survived | Actual: Survived\n",
      "Passenger 3 | Prob: 0.899 | Pred: Survived | Actual: Died\n",
      "Passenger 4 | Prob: 0.764 | Pred: Survived | Actual: Died\n",
      "Passenger 5 | Prob: 0.795 | Pred: Survived | Actual: Died\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# 1. Load the data\n",
    "titanic = fetch_openml(name=\"titanic\", version=1, as_frame=True)\n",
    "df = titanic.frame\n",
    "\n",
    "# 2. Preprocessing\n",
    "df = df[['age', 'fare', 'pclass', 'survived']]\n",
    "df = df.dropna() # Logistic regression cannot handle NaN values\n",
    "\n",
    "X = df[['age', 'fare', 'pclass']].values\n",
    "y = df[['survived']].astype(int).values.reshape(-1, 1) # Force column vector (n, 1)\n",
    "\n",
    "# Feature Scaling (Crucial for Gradient Descent)\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X_scaled = (X - X_mean) / X_std\n",
    "\n",
    "# Add bias term (Intercept)\n",
    "X_scaled = np.hstack([np.ones((X_scaled.shape[0], 1)), X_scaled])\n",
    "\n",
    "# 3. Mathematical Functions\n",
    "def sigmoid(z):\n",
    "    # Correct formula: 1 / (1 + e^-z)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# 4. Logistic Regression Training\n",
    "def train_logistic_regression(X, y, lr=0.1, epochs=3000):\n",
    "    n_samples, n_features = X.shape\n",
    "    # Initialize weights as a column vector\n",
    "    w = np.zeros((n_features, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        z = X @ w\n",
    "        y_pred = sigmoid(z)\n",
    "        \n",
    "        # Gradient calculation\n",
    "        # (y_pred - y) result is (n, 1), X.T is (features, n)\n",
    "        dw = (1/n_samples) * (X.T @ (y_pred - y))\n",
    "        w -= lr * dw\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            loss = binary_cross_entropy(y, y_pred)\n",
    "            print(f\"Epoch {epoch:4d}, Loss: {loss:.4f}\")\n",
    "    return w\n",
    "\n",
    "# 5. Execution\n",
    "weights = train_logistic_regression(X_scaled, y, lr=0.1, epochs=3000)\n",
    "\n",
    "# 6. Prediction Logic\n",
    "def predict_proba(X, w):\n",
    "    return sigmoid(X @ w)\n",
    "\n",
    "def predict_class(y_prob, threshold=0.5):\n",
    "    # Fixed the variable name bug here\n",
    "    return (y_prob >= threshold).astype(int)\n",
    "\n",
    "y_prob = predict_proba(X_scaled, weights)\n",
    "y_pred = predict_class(y_prob)\n",
    "\n",
    "# 7. Evaluate\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(f\"\\nFinal Training Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 8. Inspect specific predictions\n",
    "print(\"\\n--- Sample Predictions ---\")\n",
    "for i in range(5):\n",
    "    status = \"Survived\" if y[i] == 1 else \"Died\"\n",
    "    pred_status = \"Survived\" if y_pred[i] == 1 else \"Died\"\n",
    "    print(f\"Passenger {i+1} | Prob: {y_prob[i][0]:.3f} | Pred: {pred_status} | Actual: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee7c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f47bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4e3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302edd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc2780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4d306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17965939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441ad33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
