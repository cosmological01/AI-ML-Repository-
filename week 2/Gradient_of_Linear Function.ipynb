{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Linear Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x: [1. 2.]\n",
      "Input y = W.x: [4. 6.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Weight matrix (2 outputs, 2 inputs)\n",
    "W = np.array([\n",
    "    [2.0,1.0],\n",
    "    [0.0, 3.0]\n",
    "])\n",
    "\n",
    "# Input vector\n",
    "x = np.array([1.0,2.0])\n",
    "# Forward pass\n",
    "y = W@x\n",
    "print(\"Input x:\", x)\n",
    "print(\"Input y = W.x:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "* Each output is a weighted sum of inputs\n",
    "* No nonlinearity, no interaction terms\n",
    "* Pure linear dependence\n",
    "\n",
    "### 2. Make dependencies explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 depends on as: 4.0\n",
      "y2 depends on as: 6.0\n"
     ]
    }
   ],
   "source": [
    "y1 = W[0,0]*x[0] + W[0,1]*x[1]\n",
    "y2 = W[1,0]*x[0] + W[1,1]*x[1]\n",
    "\n",
    "print(\"y1 depends on as:\",y1)\n",
    "print(\"y2 depends on as:\",y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key idea\n",
    "* Every input contributes to multiple outputs\n",
    "* During backprop, each input must collect blame from all outputs it influenced\n",
    "\n",
    "### 3. Introduce a loss signal from above\n",
    "In ML, gradients usually come from a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient coming form loss: [ 1. -2.]\n"
     ]
    }
   ],
   "source": [
    "dL_dy = np.array([1.0,-2.0])\n",
    "print(\"Gradient coming form loss:\", dL_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This means:\n",
    "* First output wants to increase\n",
    "* Second output wants to decrease\n",
    "\n",
    "### 4. Backpropagate to the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient wrt input x: [ 2. -5.]\n"
     ]
    }
   ],
   "source": [
    "dL_dx = W.T@dL_dy\n",
    "print(\"Gradient wrt input x:\", dL_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why the transpose appears\n",
    "* Each input must sum contributions from all outputs\n",
    "* Columns of W represent how one input affects all outputs\n",
    "* Transpose turns columns into rows so dimensions align\n",
    "\n",
    "This is bookkeeping, not magic.\n",
    "### 5. See it input-by-input (core intuition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total influence on x[0]: 2.0\n",
      "Total influence on x[1]: -5.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x)):\n",
    "    contribution = dL_dy@W[:,i]\n",
    "    print(f\"Total influence on x[{i}]:\", contribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each input:\n",
    "* Looks at all outputs it affected\n",
    "* Collects weighted responsibility\n",
    "* That collection is exactly Wᵀ · dL/dy\n",
    "\n",
    "### 6. Numerical sanity check (no calculus)\n",
    "Change x slightly and observe the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical gradient wrt x[0]: 2.000000000279556\n",
      "Backprop gradient wrt x[0]: 2.0\n"
     ]
    }
   ],
   "source": [
    "epsilon  = 1e-6\n",
    "# Fake loss: L = y.dL_dy\n",
    "L = y@dL_dy\n",
    "x_perturbed = x.copy()\n",
    "x_perturbed[0] += epsilon \n",
    "\n",
    "y_perturbed = W@x_perturbed\n",
    "L_perturbed = y_perturbed@dL_dy\n",
    "\n",
    "numerical_grad = (L_perturbed - L)/ epsilon\n",
    "\n",
    "print(\"Numerical gradient wrt x[0]:\",numerical_grad)\n",
    "print(\"Backprop gradient wrt x[0]:\",dL_dx[0])\n",
    "\n",
    "# They match.\n",
    "# That’s the confirmation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ML takeaway\n",
    "* Linear layers distribute influence forward via W\n",
    "* Backprop gathers influence backward via Wᵀ\n",
    "* Transpose simply reverses the direction of responsibility\n",
    "* This is the backbone of all neural network training\n",
    "\n",
    "#### Practice suggestions\n",
    "* Change W to a non-square matrix\n",
    "* Increase input dimension to 3 or 4\n",
    "* Chain two linear layers and backprop through both\n",
    "* Print shapes at every step until it feels obvious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
