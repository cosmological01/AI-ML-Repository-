{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõ†Ô∏è Scikit-Learn Essential Cheat Sheet1. \n",
    "\n",
    "Core scikit-learn API \n",
    "\n",
    "This is the heart of sklearn. Almost every model follows this pattern.\n",
    "\n",
    "The Universal Pattern\n",
    "\n",
    "- model = Model(parameters)\n",
    "- model.fit(X_train, y_train)\n",
    "- predictions = model.predict(X_test)\n",
    "\n",
    "Methods you MUST know \n",
    "- fit(): Trains the model on the data.\n",
    "- predict(): Generates predictions.\n",
    "- predict_proba(): Returns probability estimates (for classification).\n",
    "- score(): Returns the coefficient of determination or accuracy.\n",
    "- get_params() / set_params(): View or modify model hyperparameters.\n",
    "-----------\n",
    "2. Dataset Handling (sklearn.datasets)\n",
    "\n",
    "Used for practice and prototyping without worrying about external CSVs.\n",
    "\n",
    "Important Functions\n",
    "- Classification: load_iris(), load_breast_cancer(), load_digits()\n",
    "- Regression: load_diabetes(), fetch_california_housing()\n",
    "- Synthetic Data: make_classification(), make_regression(), make_blobs()\n",
    "--------\n",
    "3. Train-Test Split & Validation (sklearn.model_selection)\n",
    "\n",
    "Essential for preventing overfitting and ensuring your model generalizes to new data.\n",
    "- train_test_split(): Splitting data into training and testing sets.\n",
    "- KFold() / StratifiedKFold(): For robust cross-validation.\n",
    "- cross_val_score(): Quickly evaluate a model using cross-validation.\n",
    "- GridSearchCV() / RandomizedSearchCV(): Tools for hyperparameter tuning.\n",
    "--------------\n",
    "4. Preprocessing & Feature Engineering (sklearn.preprocessing)\n",
    "\n",
    "Critical for handling real-world data scales and types.\n",
    "- Scaling: StandardScaler(), MinMaxScaler(), RobustScaler()\n",
    "- Encoding: OneHotEncoder(), LabelEncoder()\n",
    "- Feature Creation: PolynomialFeatures()\n",
    "\n",
    "5. Pipelines (sklearn.pipeline)\n",
    "\n",
    "Pipelines bundle preprocessing and modeling into a single object, preventing data leakage.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "\n",
    "6. Supervised Learning Models (CORE SET)\n",
    "\n",
    "|Regression Models|Classification Models|\n",
    "|---|---|\n",
    "|LinearRegression()|LogisticRegression()|\n",
    "|Ridge() / Lasso()|KNeighborsClassifier()|\n",
    "|RandomForestRegressor()|RandomForestClassifier()|\n",
    "|SVR() (Support Vector)|SVC()|\n",
    "|DecisionTreeRegressor()|GaussianNB()|\n",
    "\n",
    "7. Model Evaluation (sklearn.metrics)\n",
    "\n",
    "How we measure if the model is actually \"good.\n",
    "\n",
    "\"Classification Metrics\n",
    "- accuracy_score(), precision_score(), recall_score(), f1_score()\n",
    "- confusion_matrix(), classification_report()roc_auc_score()\n",
    "\n",
    "Regression Metrics\n",
    "- mean_squared_error() (MSE)\n",
    "- mean_absolute_error() (MAE)\n",
    "- r2_score()\n",
    "\n",
    "8. Feature Selection (sklearn.feature_selection)\n",
    "\n",
    "Used for improving performance and interpretability by removing \"noise\" features.\n",
    "\n",
    "- SelectKBest(): Selects features based on statistical tests.\n",
    "- RFE(): Recursive Feature Elimination.\n",
    "\n",
    "9. Dimensionality Reduction (sklearn.decomposition)\n",
    "\n",
    "- PCA(): Principal Component Analysis for reducing feature count while keeping variance.\n",
    "- TruncatedSVD(): Useful for sparse data (like text).\n",
    "\n",
    "10. Ensemble Methods (High-Impact)\n",
    "\n",
    "These models combine multiple learners to create a stronger overall model.\n",
    "- RandomForestClassifier()\n",
    "- GradientBoostingClassifier()\n",
    "- AdaBoostClassifier()\n",
    "\n",
    "11. Clustering & Unsupervised Learning\n",
    "- KMeans(): Grouping data based on centroids.\n",
    "- DBSCAN(): Density-based clustering.\n",
    "- AgglomerativeClustering(): Hierarchical clustering.\n",
    "\n",
    "12. Model Persistence (Real-World Use)How to save your model so you don't have to retrain it every time.\n",
    "\n",
    "import joblib\n",
    "\n",
    "##### Save\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "\n",
    "##### Load\n",
    "loaded_model = joblib.load(\"model.pkl\")\n",
    "\n",
    "13. Visualization Helpers\n",
    "\n",
    "- plot_tree(): Visualize a Decision Tree.\n",
    "- ConfusionMatrixDisplay(): A quick way to plot confusion matrices using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
